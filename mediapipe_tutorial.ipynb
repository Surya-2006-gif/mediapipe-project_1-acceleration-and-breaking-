{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9900c7d-0361-40a6-a7e7-f613b0ce8e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6416a938-dae5-4e39-aed1-e7def4c74c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_closed = pd.DataFrame(columns=['wrist','thumb_tip','index_tip','middle_tip','ring_tip','pinky_tip'])\n",
    "df_open = pd.DataFrame(columns=['wrist','thumb_tip','index_tip','middle_tip','ring_tip','pinky_tip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0a9448c-9723-40d3-ac1e-f107c592e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define landmark indices for wrist and fingertips\n",
    "wrist_and_finger_tips = [0, 4, 8, 12, 16, 20]\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.5\n",
    ") as hands:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            continue\n",
    "\n",
    "        # Convert BGR to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_rgb.flags.writeable = False\n",
    "\n",
    "        results = hands.process(frame_rgb)\n",
    "\n",
    "        frame_rgb.flags.writeable = True\n",
    "        frame_bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        open_label = 1  # for open palm\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Draw landmarks\n",
    "                mp_drawing.draw_landmarks(frame_bgr, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Extract 2D coordinates\n",
    "                coords_2d = [(lm.x, lm.y) for lm in hand_landmarks.landmark]\n",
    "\n",
    "                # Get normalization scale: distance between landmark 0 and 12\n",
    "                p0 = coords_2d[0]\n",
    "                p12 = coords_2d[12]\n",
    "                norm_dist = math.dist(p0, p12)\n",
    "\n",
    "                if norm_dist == 0:\n",
    "                    continue  # skip bad frame\n",
    "\n",
    "                # Select only wrist and finger tip coordinates\n",
    "                selected_points = [coords_2d[i] for i in wrist_and_finger_tips]\n",
    "\n",
    "                # Normalize and make relative to wrist (point 0)\n",
    "                wrist = selected_points[0]\n",
    "                normalized_values = [((x - wrist[0]) / norm_dist, (y - wrist[1]) / norm_dist)\n",
    "                                     for (x, y) in selected_points]\n",
    "\n",
    "                distances = [np.sqrt(normalized_values[i][0]**2 + normalized_values[i][1]**2) for i in range(len(normalized_values))]\n",
    "\n",
    "\n",
    "                df_closed.loc[len(df_closed)] = distances\n",
    "\n",
    "        else:\n",
    "            print(\"No hands detected\")\n",
    "\n",
    "        frame_bgr = cv2.flip(frame_bgr, 1)\n",
    "        cv2.imshow('frame', frame_bgr)\n",
    "\n",
    "        if cv2.waitKey(10) == 27:  # ESC key\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70f70c0a-ce59-4611-a466-e8b3f5d75e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5788, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_open.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5082e593-7e96-441c-82ad-278825b8e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_open['label'] = 1 # open_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0cd9a2e-35c3-4dda-9a51-0fdbe849fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_open.to_csv('palm_open.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "838b5a96-2ddd-4534-bc56-abe5981d7dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_closed['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a2d80a1-a3af-4ceb-a525-996fdbe973d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5312, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_closed.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a7b76bf-b9b8-497a-831a-03fac2fd5d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_closed.to_csv('palm_close.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f2d57cc-67dc-41e7-a734-c90513d4077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_open,df_closed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21e98444-b3f2-415c-af24-d60e122084cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11100, 7)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d28c0e9-6b71-45a4-a1aa-6492896d7cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "766a3a5a-204a-4782-ae84-1bc6197b3e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wrist</th>\n",
       "      <th>thumb_tip</th>\n",
       "      <th>index_tip</th>\n",
       "      <th>middle_tip</th>\n",
       "      <th>ring_tip</th>\n",
       "      <th>pinky_tip</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732721</td>\n",
       "      <td>0.922441</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954563</td>\n",
       "      <td>0.836204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.393382</td>\n",
       "      <td>1.055731</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.908371</td>\n",
       "      <td>0.891191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.886765</td>\n",
       "      <td>0.973209</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978824</td>\n",
       "      <td>0.956492</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3914</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.269312</td>\n",
       "      <td>1.061261</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.925815</td>\n",
       "      <td>0.959913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.644761</td>\n",
       "      <td>0.959993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942137</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628129</td>\n",
       "      <td>0.954746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945517</td>\n",
       "      <td>0.826438</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.630339</td>\n",
       "      <td>1.151959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.895687</td>\n",
       "      <td>0.936185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.647944</td>\n",
       "      <td>0.948598</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.963885</td>\n",
       "      <td>0.816461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.595641</td>\n",
       "      <td>0.951154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.938928</td>\n",
       "      <td>0.779994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.572386</td>\n",
       "      <td>1.037592</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990750</td>\n",
       "      <td>1.001415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      wrist  thumb_tip  index_tip  middle_tip  ring_tip  pinky_tip  label\n",
       "515     0.0   0.732721   0.922441         1.0  0.954563   0.836204      1\n",
       "1736    0.0   1.393382   1.055731         1.0  0.908371   0.891191      0\n",
       "1067    0.0   0.886765   0.973209         1.0  0.978824   0.956492      0\n",
       "3914    0.0   1.269312   1.061261         1.0  0.925815   0.959913      0\n",
       "3126    0.0   0.644761   0.959993         1.0  0.942137   0.810127      1\n",
       "...     ...        ...        ...         ...       ...        ...    ...\n",
       "3757    0.0   0.628129   0.954746         1.0  0.945517   0.826438      1\n",
       "2761    0.0   1.630339   1.151959         1.0  0.895687   0.936185      0\n",
       "4008    0.0   0.647944   0.948598         1.0  0.963885   0.816461      1\n",
       "3885    0.0   0.595641   0.951154         1.0  0.938928   0.779994      1\n",
       "62      0.0   1.572386   1.037592         1.0  0.990750   1.001415      0\n",
       "\n",
       "[11100 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(frac=1,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70e09e2a-6ebf-4c2e-ab51-a9d5c7691fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['thumb_tip','index_tip','ring_tip','pinky_tip']].values\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64b1ff17-9672-4b3a-a8fd-30d846d852ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11100, 4) (11100,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape,y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17ca32b9-6e06-40aa-ab58-87e04005f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42aef5c8-6cbb-405a-aa6e-fea753638f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1041\n",
      "           1       1.00      1.00      1.00      1179\n",
      "\n",
      "    accuracy                           1.00      2220\n",
      "   macro avg       1.00      1.00      1.00      2220\n",
      "weighted avg       1.00      1.00      1.00      2220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svc_model.fit(x_train,y_train)\n",
    "y_pred = svc_model.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a952695-9f76-4e03-a419-cab0bc056b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import mediapipe as mp\n",
    "import pydirectinput\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "with open('svc_model.pkl','rb') as file:\n",
    "\n",
    "    svc_model = pickle.load(file)\n",
    "\n",
    "# Initialize Mediapipe Hands and Drawing\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define landmark indices for wrist and fingertips\n",
    "wrist_and_finger_tips = [0, 4, 8, 12, 16, 20]\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.5\n",
    ") as hands:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            continue\n",
    "\n",
    "        # Convert BGR to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_rgb.flags.writeable = False\n",
    "        results = hands.process(frame_rgb)\n",
    "        frame_rgb.flags.writeable = True\n",
    "        frame_bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "        frame = cv2.flip(frame_bgr, 1)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Draw landmarks\n",
    "                mp_drawing.draw_landmarks(frame_bgr, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Extract 2D coordinates\n",
    "                coords_2d = np.array(\n",
    "                    [(int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])) for lm in hand_landmarks.landmark],\n",
    "                    dtype=np.int32\n",
    "                )\n",
    "\n",
    "                # Get normalization scale: distance between landmark 0 and 12\n",
    "                p0 = coords_2d[0]\n",
    "                p12 = coords_2d[12]\n",
    "                norm_dist = math.dist(p0, p12)\n",
    "\n",
    "                if norm_dist == 0:\n",
    "                    continue  # skip bad frame\n",
    "\n",
    "                # Select only wrist and finger tip coordinates\n",
    "                selected_points = [coords_2d[i] for i in wrist_and_finger_tips]\n",
    "\n",
    "                # Normalize and make relative to wrist (point 0)\n",
    "                wrist = selected_points[0]\n",
    "                normalized_values = [\n",
    "                    ((x - wrist[0]) / norm_dist, (y - wrist[1]) / norm_dist)\n",
    "                    for (x, y) in selected_points\n",
    "                ]\n",
    "\n",
    "                distances = [\n",
    "                    np.sqrt(x**2 + y**2)\n",
    "                    for (x, y) in normalized_values\n",
    "                ]\n",
    "\n",
    "                # Remove unwanted distances (index 0 = wrist, index 3 = middle finger)\n",
    "                distances.pop(3)\n",
    "                distances.pop(0)\n",
    "\n",
    "                # Predict using pre-trained model (assume svc_model is already loaded)\n",
    "                pred_prob = svc_model.predict([distances])\n",
    "\n",
    "                # Get bounding box and draw\n",
    "                x, y, w, h = cv2.boundingRect(coords_2d)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f'pred_prob: {pred_prob}', (x, y - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                if pred_prob == 1:\n",
    "                    pydirectinput.keyDown('w')\n",
    "                    time.sleep(1)\n",
    "                    pydirectinput.keyUp('w')\n",
    "                elif pred_prob == 0:\n",
    "                    pydirectinput.keyDown('space')\n",
    "                    time.sleep(1)\n",
    "                    pydirectinput.keyUp('space')\n",
    "        else:\n",
    "            print(\"No hands detected\")\n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        if cv2.waitKey(10) == 27:  # ESC key\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3e1998-08c4-4ec7-87f3-fcfa45629c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a26b2-ce44-479f-9954-a0b565d427bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv] *",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
